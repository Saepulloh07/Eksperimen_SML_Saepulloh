name: CI - Retrain & Build Docker Image

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.12"
  WORKING_DIR: "Workflow-CI-Saepulloh/MLProject"

jobs:
  retrain-and-build-docker:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/conda.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy scikit-learn mlflow matplotlib seaborn python-dotenv dagshub

      - name: Verify Installation
        run: |
          python --version
          pip list | grep -E "mlflow|pandas|scikit-learn"
          which mlflow

      - name: Setup DagsHub Credentials
        env:
          DAGSHUB_USERNAME: ${{ secrets.DAGSHUB_USERNAME }}
          DAGSHUB_REPO: ${{ secrets.DAGSHUB_REPO }}
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
        run: |
          # Configure DagsHub if credentials available
          if [ -n "$DAGSHUB_TOKEN" ] && [ -n "$DAGSHUB_USERNAME" ] && [ -n "$DAGSHUB_REPO" ]; then
            echo "Configuring DagsHub tracking..."
            export MLFLOW_TRACKING_URI="https://dagshub.com/${DAGSHUB_USERNAME}/${DAGSHUB_REPO}.mlflow"
            export MLFLOW_TRACKING_USERNAME="${DAGSHUB_USERNAME}"
            export MLFLOW_TRACKING_PASSWORD="${DAGSHUB_TOKEN}"
            echo "MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI}" >> $GITHUB_ENV
            echo "MLFLOW_TRACKING_USERNAME=${MLFLOW_TRACKING_USERNAME}" >> $GITHUB_ENV
            echo "MLFLOW_TRACKING_PASSWORD=${MLFLOW_TRACKING_PASSWORD}" >> $GITHUB_ENV
            echo "âœ… DagsHub configured"
          else
            echo "Using local MLflow tracking"
          fi

      - name: Check Data Files
        run: |
          cd ${{ env.WORKING_DIR }}

          if [ ! -f "data/preprocessing_objects.pkl" ]; then
            echo "ERROR: preprocessing_objects.pkl not found!"
            echo "Available files in data/:"
            ls -la data/ 2>/dev/null || echo "data/ directory not found"
            exit 1
          fi

          echo "âœ… Data files verified"
          ls -lh data/preprocessing_objects.pkl

      - name: Run Model Training
        run: |
          cd ${{ env.WORKING_DIR }}

          echo "Starting model training..."
          echo "Working directory: $(pwd)"

          # Run training directly with Python
          python modelling.py --model_name all

          echo "âœ… Training completed successfully"

      - name: Get Latest Parent Run ID (Deployment Run)
        id: get_run_id
        run: |
          cd ${{ env.WORKING_DIR }}

          python - <<'PY'
          import mlflow
          from mlflow.tracking import MlflowClient
          import os

          client = MlflowClient()

          exp = client.get_experiment_by_name("Heart_Disease_Classification")
          if not exp:
              print("ERROR: Experiment tidak ditemukan!")
              exit(1)

          # Cari run dengan nama "Best_Model_Deployment" terbaru
          runs = client.search_runs(
              experiment_ids=[exp.experiment_id],
              filter_string='tags.mlflow.runName = "Best_Model_Deployment"',
              order_by=["start_time DESC"],
              max_results=1
          )

          if not runs:
              print("ERROR: Tidak ada run 'Best_Model_Deployment'!")
              exit(1)

          run = runs[0]
          run_id = run.info.run_id
          best_model = run.data.params.get("best_model_name", "Unknown")

          with open(os.environ["GITHUB_ENV"], "a") as f:
              f.write(f"LATEST_RUN_ID={run_id}\n")
              f.write(f"BEST_MODEL_NAME={best_model}\n")

          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
              f.write(f"run_id={run_id}\n")
              f.write(f"best_model_name={best_model}\n")

          print(f"Latest Deployment Run ID: {run_id}")
          print(f"Best Model: {best_model}")
          PY

      - name: Build Docker Image with MLflow (FIXED)
        run: |
          cd ${{ env.WORKING_DIR }}

          echo "Building Docker image dari run: ${{ env.LATEST_RUN_ID }}"

          mlflow models build-docker \
            --model-uri "runs:/${{ env.LATEST_RUN_ID }}/best_model" \
            --name "${{ secrets.DOCKER_USERNAME }}/heart-disease-model" \
            --enable-mlserver

          echo "Docker image berhasil dibuat!"

      - name: Verify Model Artifact and Structure
        run: |
          cd ${{ env.WORKING_DIR }}

          echo "Checking artifacts for run: ${{ env.LATEST_RUN_ID }}"
          echo "Best model name: ${{ env.BEST_MODEL_NAME }}"

          python -c "
          import mlflow
          import os

          mlflow.set_tracking_uri('file:./mlruns')
          client = mlflow.tracking.MlflowClient()

          run_id = '${{ env.LATEST_RUN_ID }}'

          try:
              # List all artifacts recursively
              def list_artifacts_recursive(run_id, path=''):
                  artifacts = client.list_artifacts(run_id, path)
                  result = []
                  for artifact in artifacts:
                      result.append(artifact)
                      if artifact.is_dir:
                          result.extend(list_artifacts_recursive(run_id, artifact.path))
                  return result
              
              all_artifacts = list_artifacts_recursive(run_id)
              
              print('ğŸ“¦ Available artifacts:')
              for artifact in all_artifacts:
                  prefix = 'ğŸ“' if artifact.is_dir else 'ğŸ“„'
                  print(f'  {prefix} {artifact.path}')
              
              # Check if best_model exists
              has_best_model = any('best_model' in a.path for a in all_artifacts)
              
              if not has_best_model:
                  print('\nâš ï¸  WARNING: best_model artifact not found in parent run!')
                  print('Checking nested runs...')
                  
                  # Get nested runs
                  experiment = client.get_experiment_by_name('Heart_Disease_Classification')
                  nested_runs = client.search_runs(
                      experiment_ids=[experiment.experiment_id],
                      filter_string=f'tags.mlflow.parentRunId = \"{run_id}\"'
                  )
                  
                  print(f'Found {len(nested_runs)} nested runs')
                  
                  # Still proceed - model file should exist locally
                  if not os.path.exists('data/best_model_${{ env.BEST_MODEL_NAME }}.pkl'):
                      print('âŒ ERROR: Best model pickle file not found!')
                      exit(1)
                  
                  print('âœ… Best model pickle file exists locally')
              else:
                  print('\nâœ… Model artifacts verified in MLflow')
              
          except Exception as e:
              print(f'ERROR: {e}')
              import traceback
              traceback.print_exc()
              exit(1)
          "

      - name: Verify Local Model File
        run: |
          cd ${{ env.WORKING_DIR }}

          echo "Checking local model files..."
          ls -lh data/best_model_*.pkl

          if [ ! -f "data/best_model_${{ env.BEST_MODEL_NAME }}.pkl" ]; then
            echo "ERROR: Best model file not found!"
            exit 1
          fi

          echo "âœ… Local model file verified"

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build Docker Image with MLflow
        run: |
          cd ${{ env.WORKING_DIR }}

          echo "Building Docker image from MLflow model..."
          echo "Run ID: ${{ env.LATEST_RUN_ID }}"
          echo "Best Model: ${{ env.BEST_MODEL_NAME }}"

          # Build Docker image using MLflow
          mlflow models build-docker \
            --model-uri "runs:/${{ env.LATEST_RUN_ID }}/best_model" \
            --name "${{ secrets.DOCKER_USERNAME }}/heart-disease-model" \
            --enable-mlserver || {
              echo "âŒ MLflow Docker build failed"
              echo "Attempting alternative build method..."
              
              # Fallback: Create simple Dockerfile and build manually
              echo "Creating fallback Dockerfile..."
              exit 1
            }

          echo "âœ… Docker image built successfully"

      - name: Tag and Push Docker Images
        run: |
          IMAGE_BASE="${{ secrets.DOCKER_USERNAME }}/heart-disease-model"
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          RUN_ID="${{ env.LATEST_RUN_ID }}"
          SHORT_RUN_ID="${RUN_ID:0:8}"

          echo "Tagging and pushing images..."

          # Tag with multiple versions
          docker tag "${IMAGE_BASE}:latest" "${IMAGE_BASE}:latest"
          docker tag "${IMAGE_BASE}:latest" "${IMAGE_BASE}:v${TIMESTAMP}"
          docker tag "${IMAGE_BASE}:latest" "${IMAGE_BASE}:${SHORT_RUN_ID}"

          # Push all tags
          docker push "${IMAGE_BASE}:latest"
          docker push "${IMAGE_BASE}:v${TIMESTAMP}"
          docker push "${IMAGE_BASE}:${SHORT_RUN_ID}"

          # Save image info
          echo "IMAGE_LATEST=${IMAGE_BASE}:latest" >> $GITHUB_ENV
          echo "IMAGE_VERSIONED=${IMAGE_BASE}:v${TIMESTAMP}" >> $GITHUB_ENV
          echo "IMAGE_RUN=${IMAGE_BASE}:${SHORT_RUN_ID}" >> $GITHUB_ENV

          echo "âœ… Docker images pushed successfully"

      - name: Test Docker Image
        run: |
          echo "Testing Docker image..."

          # Start container in background
          docker run -d -p 5000:8080 \
            --name test-container \
            ${{ env.IMAGE_LATEST }}

          # Wait for container to be ready
          sleep 10

          # Check if container is running
          if ! docker ps | grep test-container; then
            echo "âŒ Container failed to start"
            docker logs test-container
            exit 1
          fi

          echo "âœ… Docker image test passed"

          # Cleanup
          docker stop test-container
          docker rm test-container

      - name: Upload Training Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: training-artifacts
          path: |
            ${{ env.WORKING_DIR }}/csv_output/
            ${{ env.WORKING_DIR }}/data/best_model_*.pkl
          retention-days: 30

      - name: Create Summary
        run: |
          echo "## ğŸ‰ CI/CD Pipeline Completed Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ğŸ“Š Training Results" >> $GITHUB_STEP_SUMMARY
          echo "- MLflow Run ID: \`${{ env.LATEST_RUN_ID }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- Best Model: **${{ env.BEST_MODEL_NAME }}**" >> $GITHUB_STEP_SUMMARY
          echo "- Experiment: Heart_Disease_Classification" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ğŸ³ Docker Images" >> $GITHUB_STEP_SUMMARY
          echo "The following images have been pushed to Docker Hub:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- \`${{ env.IMAGE_LATEST }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- \`${{ env.IMAGE_VERSIONED }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- \`${{ env.IMAGE_RUN }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ğŸš€ Quick Start" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`bash" >> $GITHUB_STEP_SUMMARY
          echo "# Pull the latest image" >> $GITHUB_STEP_SUMMARY
          echo "docker pull ${{ env.IMAGE_LATEST }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "# Run the model server" >> $GITHUB_STEP_SUMMARY
          echo "docker run -p 5000:8080 ${{ env.IMAGE_LATEST }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "# Test the endpoint" >> $GITHUB_STEP_SUMMARY
          echo "curl http://localhost:5000/ping" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ğŸ“ˆ Model Details" >> $GITHUB_STEP_SUMMARY
          echo "- Algorithm: ${{ env.BEST_MODEL_NAME }}" >> $GITHUB_STEP_SUMMARY
          echo "- Artifacts: Uploaded to GitHub Actions" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ğŸ”— Links" >> $GITHUB_STEP_SUMMARY
          echo "- [Docker Hub Repository](https://hub.docker.com/r/${{ secrets.DOCKER_USERNAME }}/heart-disease-model)" >> $GITHUB_STEP_SUMMARY
          echo "- [MLflow Tracking UI](file://./mlruns)" >> $GITHUB_STEP_SUMMARY

      - name: Final Summary
        run: |
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘          CI/CD PIPELINE COMPLETED SUCCESSFULLY!            â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "âœ… Model retrained successfully"
          echo "âœ… Best Model: ${{ env.BEST_MODEL_NAME }}"
          echo "âœ… MLflow Run ID: ${{ env.LATEST_RUN_ID }}"
          echo "âœ… Docker images built and pushed"
          echo "âœ… Docker image tested successfully"
          echo ""
          echo "ğŸ“¦ Docker Images:"
          echo "  - ${{ env.IMAGE_LATEST }}"
          echo "  - ${{ env.IMAGE_VERSIONED }}"
          echo "  - ${{ env.IMAGE_RUN }}"
          echo ""
          echo "ğŸ”— Docker Hub: https://hub.docker.com/r/${{ secrets.DOCKER_USERNAME }}/heart-disease-model"
          echo ""
          echo "ğŸ“ Next Steps:"
          echo "  1. Pull the image: docker pull ${{ env.IMAGE_LATEST }}"
          echo "  2. Run locally: docker run -p 5000:8080 ${{ env.IMAGE_LATEST }}"
          echo "  3. Deploy to production using your preferred orchestration platform"
